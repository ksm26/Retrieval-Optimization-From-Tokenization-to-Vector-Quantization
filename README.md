# ğŸ” [Retrieval Optimization: From Tokenization to Vector Quantization](https://www.deeplearning.ai/short-courses/retrieval-optimization-from-tokenization-to-vector-quantization/)

Welcome to the "Retrieval Optimization: From Tokenization to Vector Quantization" course! ğŸ“ The course teaches you how to optimize vector search in large-scale customer-facing RAG applications.

## ğŸ“˜ Course Summary
In this course, youâ€™ll dive deep into tokenization and vector quantization techniques, exploring how to optimize search in large-scale Retrieval-Augmented Generation (RAG) systems. Learn how different tokenization methods impact search quality and explore optimization techniques for vector search performance.

**What Youâ€™ll Learn:**
1. ğŸ§  **Embedding Models and Tokenization**: Understand the inner workings of embedding models and how text is transformed into vectors.
2. ğŸ” **Tokenization Techniques**: Explore several tokenizers like Byte-Pair Encoding, WordPiece, Unigram, and SentencePiece, and how they affect search relevancy.
3. ğŸš€ **Search Optimization**: Learn to tackle common challenges such as terminology mismatches and truncated chunks in embedding models.
4. ğŸ“Š **Search Quality Metrics**: Measure the quality of your search using various metrics and optimize search performance.
5. âš™ï¸ **HNSW Algorithm Tuning**: Adjust Hierarchical Navigable Small Worlds (HNSW) parameters to balance speed and relevance in vector search.
6. ğŸ’¾ **Vector Quantization**: Experiment with major quantization methods (product, scalar, and binary) and understand their impact on memory usage and search quality.

## ğŸ”‘ Key Points
- ğŸ§© **Tokenization in Large Models**: Learn how tokenization works in large language models and how it affects search quality.
- ğŸ› ï¸ **Training Tokenizers**: Explore how Byte-Pair Encoding, WordPiece, and Unigram are trained and function in vector search.
- ğŸ”„ **Search Optimization**: Understand how to adjust HNSW parameters and vector quantizations to optimize your retrieval systems.

## ğŸ‘¨â€ğŸ« About the Instructor
- ğŸ‘¨â€ğŸ’» **Kacper Åukawski**: Developer Relations Lead at Qdrant, Kacper brings expertise in vector search optimization and teaches practical techniques to enhance search efficiency in RAG applications.

ğŸ”— To enroll or learn more, visit ğŸ“š [deeplearning.ai](https://www.deeplearning.ai/short-courses/).
